{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PyCharter\n",
    "\n",
    "This notebook demonstrates how to test the **PyCharter** package and all 5 core services.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure the package is installed in development mode:\n",
    "\n",
    "```bash\n",
    "# From the project root directory\n",
    "pip install -e .\n",
    "# or with dev dependencies\n",
    "pip install -e \".[dev]\"\n",
    "```\n",
    "\n",
    "If you're using a Jupyter kernel in a virtual environment, make sure the kernel is using the same environment where you installed the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyCharter v0.0.2 imported successfully\n",
      "✓ Package location: /home/auscheng/statfyi/pycharter/pycharter\n",
      "✓ Is editable install: True\n"
     ]
    }
   ],
   "source": [
    "# Import pycharter and all core services\n",
    "import pycharter\n",
    "from pycharter import (\n",
    "    # Service 1: Contract Parser\n",
    "    parse_contract,\n",
    "    parse_contract_file,\n",
    "    ContractMetadata,\n",
    "    # Service 2: Metadata Store\n",
    "    MetadataStoreClient,\n",
    "    # Service 3: Pydantic Generator\n",
    "    from_dict,\n",
    "    from_json,\n",
    "    from_file,\n",
    "    from_url,\n",
    "    generate_model,\n",
    "    # Service 4: JSON Schema Converter\n",
    "    to_dict,\n",
    "    to_json,\n",
    "    to_file,\n",
    "    model_to_schema,\n",
    "    # Service 5: Runtime Validator\n",
    "    validate,\n",
    "    validate_batch,\n",
    "    ValidationResult,\n",
    ")\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"✓ PyCharter v{pycharter.__version__} imported successfully\")\n",
    "print(f\"✓ Package location: {os.path.dirname(pycharter.__file__)}\")\n",
    "print(f\"✓ Is editable install: {'site-packages' not in pycharter.__file__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 3: Pydantic Generator - Basic Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created person: Alice, age 30\n"
     ]
    }
   ],
   "source": [
    "# Define a simple JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\"},\n",
    "        \"email\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"]\n",
    "}\n",
    "\n",
    "# Generate a Pydantic model\n",
    "Person = from_dict(schema, \"Person\")\n",
    "\n",
    "# Create an instance\n",
    "person = Person(name=\"Alice\", age=30, email=\"alice@example.com\")\n",
    "print(f\"✓ Created person: {person.name}, age {person.age}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 3: Pydantic Generator - Standard JSON Schema Keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Valid instance: code=abc, status=active, score=50.0\n",
      "✓ Validation caught error: ValidationError\n"
     ]
    }
   ],
   "source": [
    "# Test standard JSON Schema keywords\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 3,\n",
    "            \"maxLength\": 10,\n",
    "            \"pattern\": \"^[a-z]+$\"\n",
    "        },\n",
    "        \"status\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"active\", \"inactive\", \"pending\"]\n",
    "        },\n",
    "        \"score\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 100\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"code\", \"status\"]\n",
    "}\n",
    "\n",
    "Model = from_dict(schema, \"TestModel\")\n",
    "\n",
    "# Valid instance\n",
    "instance = Model(code=\"abc\", status=\"active\", score=50)\n",
    "print(f\"✓ Valid instance: code={instance.code}, status={instance.status}, score={instance.score}\")\n",
    "\n",
    "# Test validation (this should raise an error)\n",
    "try:\n",
    "    invalid = Model(code=\"ab\", status=\"active\", score=50)  # Too short\n",
    "except Exception as e:\n",
    "    print(f\"✓ Validation caught error: {type(e).__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 3: Pydantic Generator - Nested Objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Nested object: Alice lives at 123 Main St, New York\n"
     ]
    }
   ],
   "source": [
    "# Test nested objects\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"address\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"street\": {\"type\": \"string\"},\n",
    "                \"city\": {\"type\": \"string\"},\n",
    "                \"zipcode\": {\"type\": \"string\"}\n",
    "            },\n",
    "            \"required\": [\"street\", \"city\"]\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"address\"]\n",
    "}\n",
    "\n",
    "Person = from_dict(schema, \"Person\")\n",
    "\n",
    "person = Person(\n",
    "    name=\"Alice\",\n",
    "    address={\n",
    "        \"street\": \"123 Main St\",\n",
    "        \"city\": \"New York\",\n",
    "        \"zipcode\": \"10001\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Nested object: {person.name} lives at {person.address.street}, {person.address.city}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 3: Pydantic Generator - Coercion and Validation (PyCharter Extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Coercion: flight_number=123 (was string), distance=100.5 (was string)\n",
      "✓ Validation: destination=abc passed all checks\n"
     ]
    }
   ],
   "source": [
    "# Test coercion and validation\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"flight_number\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"coercion\": \"coerce_to_integer\"  # Convert string/float to int\n",
    "        },\n",
    "        \"destination\": {\n",
    "            \"type\": \"string\",\n",
    "            \"coercion\": \"coerce_to_string\",\n",
    "            \"validations\": {\n",
    "                \"min_length\": {\"threshold\": 3},\n",
    "                \"max_length\": {\"threshold\": 3},\n",
    "                \"no_capital_characters\": None,\n",
    "                \"only_allow\": {\"allowed_values\": [\"abc\", \"def\", \"ghi\"]}\n",
    "            }\n",
    "        },\n",
    "        \"distance\": {\n",
    "            \"type\": \"number\",\n",
    "            \"coercion\": \"coerce_to_float\",\n",
    "            \"validations\": {\n",
    "                \"greater_than_or_equal_to\": {\"threshold\": 0}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"flight_number\", \"destination\", \"distance\"]\n",
    "}\n",
    "\n",
    "Flight = from_dict(schema, \"Flight\")\n",
    "\n",
    "# Coercion happens automatically\n",
    "flight = Flight(\n",
    "    flight_number=\"123\",    # Coerced to int: 123\n",
    "    destination=\"abc\",      # Passes all validations\n",
    "    distance=\"100.5\"        # Coerced to float: 100.5\n",
    ")\n",
    "\n",
    "print(f\"✓ Coercion: flight_number={flight.flight_number} (was string), distance={flight.distance} (was string)\")\n",
    "print(f\"✓ Validation: destination={flight.destination} passed all checks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 1: Contract Parser\n",
    "\n",
    "Test parsing data contract files and decomposing them into metadata components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Contract parsed successfully\n",
      "  Schema keys: ['type', 'properties', 'required']\n",
      "  Owner: data-team\n",
      "  Governance rules: {'pii': True, 'retention_days': 365}\n",
      "  Metadata version: 1.0\n",
      "\n",
      "✓ Found contract file: user_contract.yaml\n",
      "  Parsed contract file successfully\n",
      "  Schema type: object\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Parse contract from dictionary\n",
    "contract_data = {\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\"},\n",
    "            \"age\": {\"type\": \"integer\"}\n",
    "        },\n",
    "        \"required\": [\"name\"]\n",
    "    },\n",
    "    \"ownership\": {\n",
    "        \"owner\": \"data-team\",\n",
    "        \"team\": \"engineering\"\n",
    "    },\n",
    "    \"governance_rules\": {\n",
    "        \"pii\": True,\n",
    "        \"retention_days\": 365\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"User contract\"\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata = parse_contract(contract_data)\n",
    "print(\"✓ Contract parsed successfully\")\n",
    "print(f\"  Schema keys: {list(metadata.schema.keys())}\")\n",
    "print(f\"  Owner: {metadata.ownership.get('owner')}\")\n",
    "print(f\"  Governance rules: {metadata.governance_rules}\")\n",
    "print(f\"  Metadata version: {metadata.metadata.get('version')}\")\n",
    "\n",
    "# Test 2: Parse contract file (if available)\n",
    "data_dir = Path(\"../data/contracts\")\n",
    "if data_dir.exists():\n",
    "    contract_files = list(data_dir.glob(\"*.yaml\")) + list(data_dir.glob(\"*.json\"))\n",
    "    if contract_files:\n",
    "        contract_file = contract_files[0]\n",
    "        print(f\"\\n✓ Found contract file: {contract_file.name}\")\n",
    "        try:\n",
    "            file_metadata = parse_contract_file(str(contract_file))\n",
    "            print(f\"  Parsed contract file successfully\")\n",
    "            print(f\"  Schema type: {file_metadata.schema.get('type', 'N/A')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Note: Could not parse file ({e})\")\n",
    "    else:\n",
    "        print(\"\\n  Note: No contract files found in data/contracts/\")\n",
    "else:\n",
    "    print(\"\\n  Note: data/contracts/ directory not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Connected to metadata store\n",
      "  ✓ Stored schema 'product' v1.0 (ID: schema_1)\n",
      "  ✓ Stored ownership for schema_1\n",
      "\n",
      "✓ Retrieved schema: object with 2 properties\n",
      "✓ Retrieved ownership: product-team from engineering\n"
     ]
    }
   ],
   "source": [
    "# Create an in-memory metadata store for testing\n",
    "class InMemoryMetadataStore(MetadataStoreClient):\n",
    "    \"\"\"Simple in-memory implementation for testing.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._schemas = {}\n",
    "        self._ownership = {}\n",
    "        self._governance = {}\n",
    "        self._next_id = 1\n",
    "    \n",
    "    def connect(self):\n",
    "        self._connection = \"connected\"\n",
    "        print(\"  ✓ Connected to metadata store\")\n",
    "    \n",
    "    def disconnect(self):\n",
    "        self._connection = None\n",
    "    \n",
    "    def store_schema(self, schema_name: str, schema: dict, version: str = None):\n",
    "        schema_id = f\"schema_{self._next_id}\"\n",
    "        self._next_id += 1\n",
    "        self._schemas[schema_id] = {\n",
    "            \"id\": schema_id,\n",
    "            \"name\": schema_name,\n",
    "            \"version\": version,\n",
    "            \"schema\": schema,\n",
    "        }\n",
    "        print(f\"  ✓ Stored schema '{schema_name}' v{version} (ID: {schema_id})\")\n",
    "        return schema_id\n",
    "    \n",
    "    def get_schema(self, schema_id: str):\n",
    "        if schema_id in self._schemas:\n",
    "            return self._schemas[schema_id][\"schema\"]\n",
    "        return None\n",
    "    \n",
    "    def store_ownership(self, resource_id: str, owner: str, team: str = None, additional_info: dict = None):\n",
    "        self._ownership[resource_id] = {\n",
    "            \"owner\": owner,\n",
    "            \"team\": team,\n",
    "            \"additional_info\": additional_info or {}\n",
    "        }\n",
    "        print(f\"  ✓ Stored ownership for {resource_id}\")\n",
    "        return resource_id\n",
    "    \n",
    "    def get_ownership(self, resource_id: str):\n",
    "        return self._ownership.get(resource_id)\n",
    "\n",
    "# Test metadata store\n",
    "store = InMemoryMetadataStore()\n",
    "store.connect()\n",
    "\n",
    "# Store a schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"product_id\": {\"type\": \"string\"},\n",
    "        \"price\": {\"type\": \"number\"}\n",
    "    }\n",
    "}\n",
    "schema_id = store.store_schema(\"product\", schema, version=\"1.0\")\n",
    "\n",
    "# Store ownership\n",
    "store.store_ownership(schema_id, owner=\"product-team\", team=\"engineering\")\n",
    "\n",
    "# Retrieve schema\n",
    "retrieved_schema = store.get_schema(schema_id)\n",
    "print(f\"\\n✓ Retrieved schema: {retrieved_schema.get('type')} with {len(retrieved_schema.get('properties', {}))} properties\")\n",
    "\n",
    "# Retrieve ownership\n",
    "ownership = store.get_ownership(schema_id)\n",
    "print(f\"✓ Retrieved ownership: {ownership.get('owner')} from {ownership.get('team')}\")\n",
    "\n",
    "store.disconnect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 4: JSON Schema Converter\n",
    "\n",
    "Test converting Pydantic models back to JSON Schema format (reverse conversion).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Converted Pydantic model to JSON Schema\n",
      "  Schema type: object\n",
      "  Properties: ['product_id', 'name', 'price', 'in_stock', 'tags']\n",
      "  Price type: number\n",
      "  Price minimum: 0\n",
      "\n",
      "✓ Converted to JSON string (787 characters)\n",
      "\n",
      "✓ Round-trip test:\n",
      "  Original schema has 5 properties\n",
      "  Round-trip schema has 5 properties\n",
      "  Round-trip successful: True\n"
     ]
    }
   ],
   "source": [
    "# Create a Pydantic model first\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Product(BaseModel):\n",
    "    \"\"\"Product model for testing reverse conversion.\"\"\"\n",
    "    product_id: str = Field(description=\"Unique product identifier\")\n",
    "    name: str = Field(min_length=1, max_length=100)\n",
    "    price: float = Field(ge=0, description=\"Product price in USD\")\n",
    "    in_stock: bool = Field(default=True)\n",
    "    tags: list[str] = Field(default_factory=list)\n",
    "\n",
    "# Convert model to JSON Schema\n",
    "schema_dict = to_dict(Product)\n",
    "print(\"✓ Converted Pydantic model to JSON Schema\")\n",
    "print(f\"  Schema type: {schema_dict.get('type')}\")\n",
    "print(f\"  Properties: {list(schema_dict.get('properties', {}).keys())}\")\n",
    "\n",
    "# Check specific field constraints\n",
    "price_prop = schema_dict.get('properties', {}).get('price', {})\n",
    "print(f\"  Price type: {price_prop.get('type')}\")\n",
    "print(f\"  Price minimum: {price_prop.get('minimum')}\")\n",
    "\n",
    "# Convert to JSON string\n",
    "schema_json = to_json(Product)\n",
    "print(f\"\\n✓ Converted to JSON string ({len(schema_json)} characters)\")\n",
    "\n",
    "# Round-trip test: schema → model → schema\n",
    "print(\"\\n✓ Round-trip test:\")\n",
    "ProductModel2 = from_dict(schema_dict, \"Product2\")\n",
    "schema_dict2 = to_dict(ProductModel2)\n",
    "print(f\"  Original schema has {len(schema_dict.get('properties', {}))} properties\")\n",
    "print(f\"  Round-trip schema has {len(schema_dict2.get('properties', {}))} properties\")\n",
    "print(f\"  Round-trip successful: {len(schema_dict.get('properties', {})) == len(schema_dict2.get('properties', {}))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 4: JSON Schema Converter - Nested Models\n",
    "\n",
    "Test converting Pydantic models with nested structures back to JSON Schema format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Example 1: Simple Nested Models\n",
      "======================================================================\n",
      "\n",
      "✓ Converted Person model with nested Address and Contact\n",
      "  Top-level properties: ['name', 'age', 'address', 'contact']\n",
      "\n",
      "  Address (nested) schema:\n",
      "    Type: object\n",
      "    Properties: ['street', 'city', 'state', 'zipcode']\n",
      "    Required: ['street', 'city', 'state', 'zipcode']\n",
      "\n",
      "  Contact (nested) schema:\n",
      "    Type: object\n",
      "    Properties: ['email', 'phone']\n",
      "\n",
      "  Nested constraints preserved:\n",
      "    Address.street minLength: 1\n",
      "    Address.zipcode pattern: ^\\d{5}(-\\d{4})?$\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple nested models\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 1: Simple Nested Models\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define nested models\n",
    "class Address(BaseModel):\n",
    "    \"\"\"Address information.\"\"\"\n",
    "    street: str = Field(..., min_length=1)\n",
    "    city: str = Field(..., min_length=1)\n",
    "    state: str = Field(..., min_length=2, max_length=2)\n",
    "    zipcode: str = Field(..., pattern=\"^\\\\d{5}(-\\\\d{4})?$\")\n",
    "\n",
    "class Contact(BaseModel):\n",
    "    \"\"\"Contact information.\"\"\"\n",
    "    email: str = Field(..., description=\"Email address\")\n",
    "    phone: str = Field(default=\"\", description=\"Phone number\")\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Person with nested address and contact.\"\"\"\n",
    "    name: str = Field(..., min_length=1)\n",
    "    age: int = Field(..., ge=0, le=150)\n",
    "    address: Address  # Nested model\n",
    "    contact: Contact  # Nested model\n",
    "\n",
    "# Convert to schema\n",
    "schema = to_dict(Person)\n",
    "\n",
    "print(f\"\\n✓ Converted Person model with nested Address and Contact\")\n",
    "print(f\"  Top-level properties: {list(schema.get('properties', {}).keys())}\")\n",
    "\n",
    "# Check nested address schema\n",
    "address_prop = schema.get('properties', {}).get('address', {})\n",
    "print(f\"\\n  Address (nested) schema:\")\n",
    "print(f\"    Type: {address_prop.get('type')}\")\n",
    "print(f\"    Properties: {list(address_prop.get('properties', {}).keys())}\")\n",
    "print(f\"    Required: {address_prop.get('required', [])}\")\n",
    "\n",
    "# Check nested contact schema\n",
    "contact_prop = schema.get('properties', {}).get('contact', {})\n",
    "print(f\"\\n  Contact (nested) schema:\")\n",
    "print(f\"    Type: {contact_prop.get('type')}\")\n",
    "print(f\"    Properties: {list(contact_prop.get('properties', {}).keys())}\")\n",
    "\n",
    "# Verify nested constraints are preserved\n",
    "address_street = address_prop.get('properties', {}).get('street', {})\n",
    "address_zipcode = address_prop.get('properties', {}).get('zipcode', {})\n",
    "print(f\"\\n  Nested constraints preserved:\")\n",
    "print(f\"    Address.street minLength: {address_street.get('minLength')}\")\n",
    "print(f\"    Address.zipcode pattern: {address_zipcode.get('pattern')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minLength': 1, 'title': 'Street', 'type': 'string'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Arrays of nested models\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Example 2: Arrays of Nested Models\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define nested model\n",
    "class OrderItem(BaseModel):\n",
    "    \"\"\"Order item with product details.\"\"\"\n",
    "    product_id: str = Field(..., description=\"Product identifier\")\n",
    "    quantity: int = Field(..., ge=1, description=\"Quantity ordered\")\n",
    "    price: float = Field(..., ge=0, description=\"Unit price\")\n",
    "\n",
    "class Order(BaseModel):\n",
    "    \"\"\"Order with array of items.\"\"\"\n",
    "    order_id: str = Field(..., description=\"Order identifier\")\n",
    "    customer_id: str = Field(..., description=\"Customer identifier\")\n",
    "    items: list[OrderItem] = Field(..., min_length=1, description=\"Order items\")\n",
    "    total: float = Field(..., ge=0, description=\"Total order amount\")\n",
    "\n",
    "# Convert to schema\n",
    "schema = to_dict(Order)\n",
    "\n",
    "print(f\"\\n✓ Converted Order model with array of OrderItem\")\n",
    "print(f\"  Properties: {list(schema.get('properties', {}).keys())}\")\n",
    "\n",
    "# Check array of nested models\n",
    "items_prop = schema.get('properties', {}).get('items', {})\n",
    "print(f\"\\n  Items (array) schema:\")\n",
    "print(f\"    Type: {items_prop.get('type')}\")\n",
    "print(f\"    Min items: {items_prop.get('minItems')}\")\n",
    "\n",
    "# Check nested item schema\n",
    "item_schema = items_prop.get('items', {})\n",
    "print(f\"\\n  OrderItem (nested in array) schema:\")\n",
    "print(f\"    Type: {item_schema.get('type')}\")\n",
    "print(f\"    Properties: {list(item_schema.get('properties', {}).keys())}\")\n",
    "print(f\"    Required: {item_schema.get('required', [])}\")\n",
    "\n",
    "# Verify nested constraints\n",
    "item_quantity = item_schema.get('properties', {}).get('quantity', {})\n",
    "print(f\"\\n  Nested array item constraints preserved:\")\n",
    "print(f\"    OrderItem.quantity minimum: {item_quantity.get('minimum')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Deeply nested structures\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Example 3: Deeply Nested Structures\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Deeply nested models\n",
    "class Coordinates(BaseModel):\n",
    "    \"\"\"Geographic coordinates.\"\"\"\n",
    "    latitude: float = Field(..., ge=-90, le=90)\n",
    "    longitude: float = Field(..., ge=-180, le=180)\n",
    "\n",
    "class Location(BaseModel):\n",
    "    \"\"\"Location with coordinates.\"\"\"\n",
    "    name: str = Field(..., description=\"Location name\")\n",
    "    coordinates: Coordinates  # Nested model\n",
    "\n",
    "class Warehouse(BaseModel):\n",
    "    \"\"\"Warehouse information.\"\"\"\n",
    "    warehouse_id: str = Field(..., description=\"Warehouse identifier\")\n",
    "    location: Location  # Nested model containing another nested model\n",
    "    capacity: int = Field(..., ge=0)\n",
    "\n",
    "class Product(BaseModel):\n",
    "    \"\"\"Product with warehouse information.\"\"\"\n",
    "    product_id: str = Field(..., description=\"Product identifier\")\n",
    "    name: str = Field(..., min_length=1)\n",
    "    warehouses: list[Warehouse] = Field(default_factory=list)  # Array of nested models\n",
    "\n",
    "# Convert to schema\n",
    "schema = to_dict(Product)\n",
    "\n",
    "print(f\"\\n✓ Converted Product model with deeply nested structures\")\n",
    "print(f\"  Top-level properties: {list(schema.get('properties', {}).keys())}\")\n",
    "\n",
    "# Navigate through nested structure\n",
    "warehouses_prop = schema.get('properties', {}).get('warehouses', {})\n",
    "warehouse_item = warehouses_prop.get('items', {})\n",
    "warehouse_location = warehouse_item.get('properties', {}).get('location', {})\n",
    "location_coords = warehouse_location.get('properties', {}).get('coordinates', {})\n",
    "\n",
    "print(f\"\\n  Deep nesting structure:\")\n",
    "print(f\"    Product.warehouses (array)\")\n",
    "print(f\"      → Warehouse.location (nested)\")\n",
    "print(f\"        → Location.coordinates (nested)\")\n",
    "print(f\"          → Coordinates.latitude/longitude\")\n",
    "\n",
    "print(f\"\\n  Deeply nested constraints preserved:\")\n",
    "lat_prop = location_coords.get('properties', {}).get('latitude', {})\n",
    "lon_prop = location_coords.get('properties', {}).get('longitude', {})\n",
    "print(f\"    Coordinates.latitude range: [{lat_prop.get('minimum')}, {lat_prop.get('maximum')}]\")\n",
    "print(f\"    Coordinates.longitude range: [{lon_prop.get('minimum')}, {lon_prop.get('maximum')}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 4: JSON Schema Converter - Nested Models from Separate Modules\n",
    "\n",
    "**Important**: Nested models do NOT need to be in the same file! The converter works with any BaseModel class that's accessible in the Python runtime, regardless of where it's defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Nested models from separate modules\n",
    "print(\"=\" * 70)\n",
    "print(\"Example: Nested Models from Separate Modules\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "# Create a temporary module file with a nested model\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "    f.write('''from pydantic import BaseModel, Field\n",
    "\n",
    "class Address(BaseModel):\n",
    "    \"\"\"Address model from separate module.\"\"\"\n",
    "    street: str = Field(..., min_length=1, description=\"Street address\")\n",
    "    city: str = Field(..., min_length=1, description=\"City name\")\n",
    "    state: str = Field(..., min_length=2, max_length=2, description=\"State code\")\n",
    "    zipcode: str = Field(..., pattern=\"^\\\\\\\\d{5}(-\\\\\\\\d{4})?$\", description=\"ZIP code\")\n",
    "''')\n",
    "    temp_module_path = f.name\n",
    "\n",
    "try:\n",
    "    # Import the module dynamically\n",
    "    spec = importlib.util.spec_from_file_location(\"temp_address_module\", temp_module_path)\n",
    "    address_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(address_module)\n",
    "    Address = address_module.Address\n",
    "    \n",
    "    # Create a model in this notebook that uses the imported model\n",
    "    class Person(BaseModel):\n",
    "        \"\"\"Person model using Address from separate module.\"\"\"\n",
    "        name: str = Field(..., min_length=1)\n",
    "        age: int = Field(..., ge=0, le=150)\n",
    "        address: Address  # Nested model from separate module\n",
    "    \n",
    "    # Convert to schema\n",
    "    schema = to_dict(Person)\n",
    "    \n",
    "    print(f\"\\n✓ Converted Person model with Address from separate module\")\n",
    "    print(f\"  Top-level properties: {list(schema.get('properties', {}).keys())}\")\n",
    "    \n",
    "    # Check nested address schema\n",
    "    address_prop = schema.get('properties', {}).get('address', {})\n",
    "    print(f\"\\n  Address (from separate module) schema:\")\n",
    "    print(f\"    Type: {address_prop.get('type')}\")\n",
    "    print(f\"    Properties: {list(address_prop.get('properties', {}).keys())}\")\n",
    "    print(f\"    Required: {address_prop.get('required', [])}\")\n",
    "    \n",
    "    # Verify constraints from separate module are preserved\n",
    "    address_street = address_prop.get('properties', {}).get('street', {})\n",
    "    address_zipcode = address_prop.get('properties', {}).get('zipcode', {})\n",
    "    print(f\"\\n  Constraints from separate module preserved:\")\n",
    "    print(f\"    Address.street minLength: {address_street.get('minLength')}\")\n",
    "    print(f\"    Address.zipcode pattern: {address_zipcode.get('pattern')}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ Key Point: Nested models can be defined in separate files/modules!\")\n",
    "    print(\"  The converter works with any BaseModel class accessible in Python runtime.\")\n",
    "    print(\"  It doesn't matter where the model is defined:\")\n",
    "    print(\"    - Same file\")\n",
    "    print(\"    - Different file in same package\")\n",
    "    print(\"    - Different package\")\n",
    "    print(\"    - Dynamically imported modules\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error testing separate modules: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Clean up\n",
    "    if os.path.exists(temp_module_path):\n",
    "        os.unlink(temp_module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Round-trip with nested models\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Example 4: Round-Trip with Nested Models\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a model with nested structure\n",
    "class Category(BaseModel):\n",
    "    name: str = Field(..., min_length=1)\n",
    "    description: str = Field(default=\"\")\n",
    "\n",
    "class Product(BaseModel):\n",
    "    product_id: str\n",
    "    name: str = Field(..., min_length=1)\n",
    "    category: Category\n",
    "    tags: list[str] = Field(default_factory=list)\n",
    "\n",
    "# Step 1: Convert model to schema\n",
    "print(\"\\n1. Pydantic model → JSON Schema\")\n",
    "original_schema = to_dict(Product)\n",
    "print(f\"   ✓ Converted Product model to schema\")\n",
    "print(f\"     Properties: {list(original_schema.get('properties', {}).keys())}\")\n",
    "\n",
    "# Check nested category\n",
    "category_prop = original_schema.get('properties', {}).get('category', {})\n",
    "print(f\"     Category (nested) properties: {list(category_prop.get('properties', {}).keys())}\")\n",
    "\n",
    "# Step 2: Convert schema back to model\n",
    "print(\"\\n2. JSON Schema → Pydantic model\")\n",
    "ProductModel2 = from_dict(original_schema, \"Product2\")\n",
    "print(f\"   ✓ Generated ProductModel2 from schema\")\n",
    "\n",
    "# Step 3: Create instance and verify\n",
    "print(\"\\n3. Create instance with nested data\")\n",
    "product = ProductModel2(\n",
    "    product_id=\"prod-123\",\n",
    "    name=\"Widget\",\n",
    "    category={\"name\": \"Electronics\", \"description\": \"Electronic items\"},\n",
    "    tags=[\"popular\", \"new\"]\n",
    ")\n",
    "print(f\"   ✓ Created product: {product.name}\")\n",
    "print(f\"   ✓ Category: {product.category.name} - {product.category.description}\")\n",
    "print(f\"   ✓ Tags: {product.tags}\")\n",
    "\n",
    "# Step 4: Convert back to schema\n",
    "print(\"\\n4. Pydantic model → JSON Schema (round-trip)\")\n",
    "round_trip_schema = to_dict(ProductModel2)\n",
    "print(f\"   ✓ Round-trip conversion successful\")\n",
    "print(f\"     Original has {len(original_schema.get('properties', {}))} properties\")\n",
    "print(f\"     Round-trip has {len(round_trip_schema.get('properties', {}))} properties\")\n",
    "\n",
    "# Verify nested structure preserved\n",
    "rt_category = round_trip_schema.get('properties', {}).get('category', {})\n",
    "print(f\"     Nested category preserved: {rt_category.get('type') == 'object'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'object',\n",
       " 'title': 'Product',\n",
       " 'description': 'Product model for testing reverse conversion.',\n",
       " 'properties': {'product_id': {'description': 'Unique product identifier',\n",
       "   'title': 'Product Id',\n",
       "   'type': 'string'},\n",
       "  'name': {'maxLength': 100,\n",
       "   'minLength': 1,\n",
       "   'title': 'Name',\n",
       "   'type': 'string'},\n",
       "  'price': {'description': 'Product price in USD',\n",
       "   'minimum': 0,\n",
       "   'title': 'Price',\n",
       "   'type': 'number'},\n",
       "  'in_stock': {'default': True, 'title': 'In Stock', 'type': 'boolean'},\n",
       "  'tags': {'items': {'type': 'string'}, 'title': 'Tags', 'type': 'array'}},\n",
       " 'required': ['product_id', 'name', 'price']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service 5: Runtime Validator\n",
    "\n",
    "Test validating data against generated Pydantic models in production scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model for validation\n",
    "validation_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"user_id\": {\"type\": \"string\", \"minLength\": 1},\n",
    "        \"email\": {\"type\": \"string\", \"pattern\": \"^[^@]+@[^@]+\\\\.[^@]+$\"},\n",
    "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 150}\n",
    "    },\n",
    "    \"required\": [\"user_id\", \"email\", \"age\"]\n",
    "}\n",
    "\n",
    "UserModel = from_dict(validation_schema, \"User\")\n",
    "\n",
    "# Test 1: Validate single valid record\n",
    "print(\"Test 1: Validate single valid record\")\n",
    "valid_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"email\": \"alice@example.com\",\n",
    "    \"age\": 30\n",
    "}\n",
    "result = validate(UserModel, valid_data)\n",
    "if result.is_valid:\n",
    "    print(f\"  ✓ Validation passed: {result.data.user_id} ({result.data.email})\")\n",
    "else:\n",
    "    print(f\"  ✗ Validation failed: {result.errors}\")\n",
    "\n",
    "# Test 2: Validate single invalid record\n",
    "print(\"\\nTest 2: Validate single invalid record\")\n",
    "invalid_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"email\": \"invalid-email\",  # Invalid email format\n",
    "    \"age\": 200  # Age too high\n",
    "}\n",
    "result = validate(UserModel, invalid_data)\n",
    "if not result.is_valid:\n",
    "    print(f\"  ✓ Validation correctly failed\")\n",
    "    print(f\"  Errors: {len(result.errors)} error(s)\")\n",
    "    for error in result.errors[:2]:  # Show first 2 errors\n",
    "        print(f\"    - {error}\")\n",
    "\n",
    "# Test 3: Validate batch\n",
    "print(\"\\nTest 3: Validate batch of records\")\n",
    "batch_data = [\n",
    "    {\"user_id\": \"user1\", \"email\": \"user1@example.com\", \"age\": 25},\n",
    "    {\"user_id\": \"user2\", \"email\": \"user2@example.com\", \"age\": 35},\n",
    "    {\"user_id\": \"user3\", \"email\": \"invalid\", \"age\": 40},  # Invalid email\n",
    "    {\"user_id\": \"user4\", \"email\": \"user4@example.com\", \"age\": -5},  # Invalid age\n",
    "]\n",
    "\n",
    "results = validate_batch(UserModel, batch_data)\n",
    "valid_count = sum(1 for r in results if r.is_valid)\n",
    "invalid_count = sum(1 for r in results if not r.is_valid)\n",
    "\n",
    "print(f\"  ✓ Batch validation complete:\")\n",
    "print(f\"    Valid records: {valid_count}/{len(batch_data)}\")\n",
    "print(f\"    Invalid records: {invalid_count}/{len(batch_data)}\")\n",
    "\n",
    "# Show valid records\n",
    "valid_records = [r.data for r in results if r.is_valid]\n",
    "print(f\"    Valid user IDs: {[r.user_id for r in valid_records]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Workflow: All 5 Services Together\n",
    "\n",
    "Demonstrate the complete data production journey from contract specification to runtime validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COMPLETE DATA PRODUCTION JOURNEY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Contract Specification (create a contract)\n",
    "print(\"\\n[Step 1] Contract Specification\")\n",
    "contract = {\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\"type\": \"string\"},\n",
    "            \"customer_id\": {\"type\": \"string\"},\n",
    "            \"total\": {\"type\": \"number\", \"minimum\": 0},\n",
    "            \"items\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"product_id\": {\"type\": \"string\"},\n",
    "                        \"quantity\": {\"type\": \"integer\", \"minimum\": 1},\n",
    "                        \"price\": {\"type\": \"number\", \"minimum\": 0}\n",
    "                    },\n",
    "                    \"required\": [\"product_id\", \"quantity\", \"price\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"order_id\", \"customer_id\", \"total\", \"items\"]\n",
    "    },\n",
    "    \"ownership\": {\n",
    "        \"owner\": \"orders-team\",\n",
    "        \"team\": \"data-engineering\"\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"Order data contract\"\n",
    "    }\n",
    "}\n",
    "print(\"  ✓ Contract defined\")\n",
    "\n",
    "# Step 2: Contract Parsing\n",
    "print(\"\\n[Step 2] Contract Parsing\")\n",
    "metadata = parse_contract(contract)\n",
    "print(f\"  ✓ Contract parsed: {len(metadata.schema.get('properties', {}))} properties\")\n",
    "print(f\"  ✓ Owner: {metadata.ownership.get('owner')}\")\n",
    "\n",
    "# Step 3: Metadata Storage\n",
    "print(\"\\n[Step 3] Metadata Storage\")\n",
    "store = InMemoryMetadataStore()\n",
    "store.connect()\n",
    "schema_id = store.store_schema(\"order\", metadata.schema, version=\"1.0\")\n",
    "store.store_ownership(schema_id, owner=metadata.ownership.get(\"owner\"), \n",
    "                     team=metadata.ownership.get(\"team\"))\n",
    "print(f\"  ✓ Metadata stored (ID: {schema_id})\")\n",
    "\n",
    "# Step 4: Pydantic Model Generation\n",
    "print(\"\\n[Step 4] Pydantic Model Generation\")\n",
    "stored_schema = store.get_schema(schema_id)\n",
    "OrderModel = from_dict(stored_schema, \"Order\")\n",
    "print(f\"  ✓ Model generated: {OrderModel.__name__}\")\n",
    "\n",
    "# Step 5: Runtime Validation\n",
    "print(\"\\n[Step 5] Runtime Validation\")\n",
    "test_order = {\n",
    "    \"order_id\": \"ORD-123\",\n",
    "    \"customer_id\": \"CUST-456\",\n",
    "    \"total\": 99.99,\n",
    "    \"items\": [\n",
    "        {\"product_id\": \"PROD-1\", \"quantity\": 2, \"price\": 49.99}\n",
    "    ]\n",
    "}\n",
    "\n",
    "result = validate(OrderModel, test_order)\n",
    "if result.is_valid:\n",
    "    print(f\"  ✓ Order validated successfully\")\n",
    "    print(f\"    Order ID: {result.data.order_id}\")\n",
    "    print(f\"    Customer: {result.data.customer_id}\")\n",
    "    print(f\"    Total: ${result.data.total}\")\n",
    "    print(f\"    Items: {len(result.data.items)}\")\n",
    "else:\n",
    "    print(f\"  ✗ Validation failed: {result.errors}\")\n",
    "\n",
    "# Bonus: JSON Schema Converter (round-trip)\n",
    "print(\"\\n[Bonus] JSON Schema Converter (Round-trip)\")\n",
    "converted_schema = to_dict(OrderModel)\n",
    "print(f\"  ✓ Model converted back to schema\")\n",
    "print(f\"    Schema has {len(converted_schema.get('properties', {}))} properties\")\n",
    "\n",
    "store.disconnect()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ Complete workflow test finished successfully!\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (charter-dev)",
   "language": "python",
   "name": "charter-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
